{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG\n",
    "\n",
    "The process of bringing the appropriate information and inserting it into the model prompt is known as **Retrieval Augmented Generation (RAG)**. Retrival Augmented Generation (RAG) is a technique that uses a large language model to generate a response based on a user's input and augmenting LLM knowledge with additional data.\n",
    "\n",
    "The RAG process involves the following steps:\n",
    "\n",
    "1. Load the documents; it could be urls, files, etc. See full list of supported loaders [here](https://python.langchain.com/v0.2/docs/integrations/document_loaders/).\n",
    "2. Split the documents into chunks.\n",
    "3. Embed the chunks texts into vectors.\n",
    "4. Store it in a vector database.\n",
    "5. Query and retrieve the similar documents from the vector database.\n",
    "\n",
    "Then use it to generate the response.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/RAG1.jpg\" width=\"666.67\" height=\"230.67\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq()\n",
    "llm.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[RecursiveCharacterTextSplitter](https://python.langchain.com/v0.2/docs/how_to/recursive_text_splitter/), will recursively split the document using common separators like new lines until each chunk is the appropriate size. This is the recommended text splitter for generic text use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `as_retriever()` to create a retriever with your vectorstore. Learn more about it [here](https://python.langchain.com/v0.2/docs/how_to/vectorstore_retriever/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Retrived documents to generate better responses from the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/RAG2.png\" width=\"506.4\" height=\"259.8\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, LangChain has two functions that implement the above LCEL:\n",
    "\n",
    "- `create_stuff_documents_chain` will \"stuff\" the retrived documents into the prompt.\n",
    "- `create_retrieval_chain` adds the retriever to get the documents that will be added and propagates the retrieved context through the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better yet, this one also returns the context of the answer which can be handy. That is basic RAG! ðŸ˜Ž"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational Retrieval Augmented Generation\n",
    "\n",
    "Now we will combine what we learned with chat history and make a Conversational RAG. To do this, we will create a subchain for our retriver, where our input will include the history of the conversation if needed. Before we were just passing the input to the retriever.\n",
    "\n",
    "Basically, we will contextualize out input with the chat history before passing it to the retriever.\n",
    "\n",
    "\n",
    "> Note that we leverage a helper function `create_history_aware_retriever` for this step, which manages the case where chat_history is empty, and otherwise applies `prompt | llm | StrOutputParser() | retriever` in sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/conversational_retrieval_chain.png\" width=\"792.5\" height=\"371.5\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we updated the main prompt to include the chat history and create the RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is done, now we put this chain into the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources/References:\n",
    "\n",
    "- https://python.langchain.com/v0.2/docs/tutorials/rag/\n",
    "- https://python.langchain.com/v0.2/docs/tutorials/qa_chat_history/\n",
    "- https://www.youtube.com/watch?v=swCPic00c30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contribute on github by making the streamlit code or this tutorial better, or PR your version of app using different document loaders instead of urls and we can add it! ðŸ˜Ž\n",
    "\n",
    "\n",
    "Next time, we will learn **Agents** and also some **LangGraph**."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
